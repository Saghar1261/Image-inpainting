{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on arbitary dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have saved the weights for the generator, discriminator, and repair_generator models. We can now test our model on any arbitrary test set to see how well it repairs damaged images. The input images should be in a 256x256 format. Additionally, the weights for the code regarding 8000 epochs are available on the Google Drive link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_147 (Dense)           (None, 256)               25856     \n",
      "                                                                 \n",
      " leaky_re_lu_110 (LeakyReLU  (None, 256)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_42 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 512)               131584    \n",
      "                                                                 \n",
      " leaky_re_lu_111 (LeakyReLU  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_43 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1024)              525312    \n",
      "                                                                 \n",
      " leaky_re_lu_112 (LeakyReLU  (None, 1024)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_44 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 49152)             50380800  \n",
      "                                                                 \n",
      " reshape_25 (Reshape)        (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51070720 (194.82 MB)\n",
      "Trainable params: 51067136 (194.81 MB)\n",
      "Non-trainable params: 3584 (14.00 KB)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_23 (Flatten)        (None, 49152)             0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1024)              50332672  \n",
      "                                                                 \n",
      " leaky_re_lu_113 (LeakyReLU  (None, 1024)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 512)               524800    \n",
      "                                                                 \n",
      " leaky_re_lu_114 (LeakyReLU  (None, 512)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50857985 (194.01 MB)\n",
      "Trainable params: 50857985 (194.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " undamaged_input (InputLaye  [(None, 128, 128, 3)]        0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " damaged_input (InputLayer)  [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential_52 (Sequential)  (None, 256)                  2529766   ['undamaged_input[0][0]',     \n",
      "                                                          4          'damaged_input[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenat  (None, 512)                  0         ['sequential_52[0][0]',       \n",
      " e)                                                                  'sequential_52[1][0]']       \n",
      "                                                                                                  \n",
      " sequential_53 (Sequential)  (None, 128, 128, 3)          5116876   ['concatenate_11[0][0]']      \n",
      "                                                          8                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 76466432 (291.70 MB)\n",
      "Trainable params: 76466432 (291.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x0000013DC3EE8680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1428 - accuracy: 1.0000\n",
      "Discriminator Loss on Generated Images: [0.14279881119728088, 1.0]\n",
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_test_function.<locals>.test_function at 0x0000013DC3E800E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1775\n",
      "Repair Generator Test Loss: 0.17745429277420044\n",
      "2/2 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, BatchNormalization, Activation, LeakyReLU, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "from PIL import UnidentifiedImageError\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import Model as KerasModel\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from scipy.linalg import sqrtm\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(1000)\n",
    "# Define image parameters\n",
    "img_rows, img_cols, channels = 128, 128, 3\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "z_dim = 100  # Size of the noise vector\n",
    "epochs = 8000\n",
    "batch_size = 64\n",
    "save_interval = 100  # Set the interval to save generated images\n",
    "\n",
    "\n",
    "\n",
    "def build_repair_generator(z_dim=100):\n",
    "    undamaged_input = Input(shape=img_shape, name='undamaged_input')\n",
    "    damaged_input = Input(shape=img_shape, name='damaged_input')\n",
    "\n",
    "    # Encoder part\n",
    "    encoder = Sequential([\n",
    "        Flatten(input_shape=img_shape),\n",
    "        Dense(512),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(256),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "    ])\n",
    "\n",
    "    undamaged_encoded = encoder(undamaged_input)\n",
    "    damaged_encoded = encoder(damaged_input)\n",
    "\n",
    "    # Concatenate encoded representations\n",
    "    merged = Concatenate()([undamaged_encoded, damaged_encoded])\n",
    "\n",
    "    # Decoder part\n",
    "    decoder = Sequential([\n",
    "        Dense(512),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(1024),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(np.prod(img_shape), activation='tanh'),\n",
    "        Reshape(img_shape),\n",
    "    ])\n",
    "\n",
    "    repaired_output = decoder(merged)\n",
    "\n",
    "    model = Model(inputs=[undamaged_input, damaged_input], outputs=repaired_output)\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "# Generator model\n",
    "def build_generator(z_dim=100):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=z_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=(z_dim,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)\n",
    "\n",
    "\n",
    "\n",
    "# Discriminator model\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    model.add(Dense(1024))  # Increased capacity\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))   # Increased capacity\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "\n",
    "# Function to normalize images to the range [-1, 1]\n",
    "def normalize_images(images):\n",
    "    return 2 * images - 1\n",
    "\n",
    "def load_and_resize_dataset(dataset_path, target_size=(128, 128), pixel_difference_threshold=50):\n",
    "    damaged_images = []\n",
    "    for filename in os.listdir(os.path.join(dataset_path, \"damaged\")):\n",
    "        try:\n",
    "            img = load_img(os.path.join(dataset_path, \"damaged\", filename), target_size=target_size)\n",
    "            img = img_to_array(img) / 128.0\n",
    "            damaged_images.append(img)\n",
    "        except UnidentifiedImageError:\n",
    "            print(f\"Skipping non-image file: {filename}\")\n",
    " \n",
    "    undamaged_images = []\n",
    "    for filename in os.listdir(os.path.join(dataset_path, \"undamaged\")):\n",
    "        try:\n",
    "            img = load_img(os.path.join(dataset_path, \"undamaged\", filename), target_size=target_size)\n",
    "            img = img_to_array(img) / 128.0\n",
    "            undamaged_images.append(img)\n",
    "        except UnidentifiedImageError:\n",
    "            print(f\"Skipping non-image file: {filename}\")\n",
    " \n",
    "    min_samples = min(len(damaged_images), len(undamaged_images))\n",
    "    damaged_images = damaged_images[:min_samples]\n",
    "    undamaged_images = undamaged_images[:min_samples]\n",
    " \n",
    "    damaged_images = np.array(damaged_images)\n",
    "    undamaged_images = np.array(undamaged_images)\n",
    " \n",
    "    # Identify damaged regions based on pixel differences\n",
    "    damaged_regions = np.sum(np.abs(undamaged_images - damaged_images), axis=-1) > pixel_difference_threshold\n",
    " \n",
    "    return damaged_images, undamaged_images, damaged_regions\n",
    "\n",
    "# Function to save generated images\n",
    "def save_generated_images(epoch, generator, output_path, X_test_undamaged, X_test_damaged, z_dim=100, r=5, c=3):\n",
    "    # Resize images to match the repair generator input shape\n",
    "    X_test_undamaged_resized = np.array([resize(img, (128, 128, 3), mode='reflect', anti_aliasing=True) for img in X_test_undamaged])\n",
    "    X_test_damaged_resized = np.array([resize(img, (128, 128, 3), mode='reflect', anti_aliasing=True) for img in X_test_damaged])\n",
    " \n",
    "    # Generate repaired images for damaged parts\n",
    "    repaired_imgs = generator.predict([X_test_undamaged_resized, X_test_damaged_resized])\n",
    " \n",
    "    # Identify damaged regions based on pixel differences\n",
    "    damaged_regions = np.sum(np.abs(X_test_undamaged_resized - X_test_damaged_resized), axis=-1) > 50\n",
    " \n",
    "    # Copy repaired parts to damaged images\n",
    "    for i in range(len(X_test_undamaged_resized)):\n",
    "        X_test_damaged_resized[i][damaged_regions[i]] = repaired_imgs[i][damaged_regions[i]]\n",
    " \n",
    "    # Rescale images to 0-1\n",
    "    X_test_undamaged_rescaled = 0.5 * (X_test_undamaged_resized + 1)\n",
    "    X_test_damaged_rescaled = 0.5 * (X_test_damaged_resized + 1)\n",
    " \n",
    "    fig, axs = plt.subplots(r, c, figsize=(15, 15))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        axs[i, 0].imshow(X_test_undamaged_rescaled[cnt])\n",
    "        axs[i, 0].axis('off')\n",
    "        axs[i, 0].set_title(\"Real (Undamaged)\")\n",
    " \n",
    "        axs[i, 1].imshow(X_test_damaged_rescaled[cnt])\n",
    "        axs[i, 1].axis('off')\n",
    "        axs[i, 1].set_title(\"Damaged\")\n",
    " \n",
    "        axs[i, 2].imshow(repaired_imgs[cnt])\n",
    "        axs[i, 2].axis('off')\n",
    "        axs[i, 2].set_title(\"Repaired\")\n",
    " \n",
    "        cnt += 1\n",
    " \n",
    "    fig.savefig(output_path + f\"/gan_repaired_image_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Adversarial ground truths\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "\n",
    "\n",
    "# Build and compile the generator\n",
    "generator = build_generator()\n",
    "generator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "generator.compile(loss='mse', optimizer=generator_optimizer)\n",
    "\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# The generator takes noise as input and generates images\n",
    "z = Input(shape=(z_dim,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model, only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "validity = discriminator(img)\n",
    "\n",
    "# Build and compile the combined model\n",
    "combined = Model(z, validity)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n",
    "\n",
    "\n",
    "# Build and compile the repair generator\n",
    "repair_generator = build_repair_generator()\n",
    "repair_generator_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "repair_generator.compile(loss='mse', optimizer=repair_generator_optimizer)\n",
    "\n",
    "\n",
    "# Test on new damaged images\n",
    "test_folder_path = r\"D:\\SagharGhaffari\\new dataset2\\new dataset\\mine\"\n",
    "output_path = r\"D:\\SagharGhaffari\\new dataset2\\new dataset\\arbitaryoutput\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load and preprocess the test dataset\n",
    "X_test_damaged_testset, X_test_undamaged_testset, damaged_regions_testset = load_and_resize_dataset(test_folder_path, target_size=(128, 128))\n",
    " \n",
    "# Combine the test sets for evaluation\n",
    "X_test_testset = np.concatenate([X_test_damaged_testset, X_test_undamaged_testset])\n",
    "\n",
    "# Resize the test images to the expected input shape of the repair generator\n",
    "X_test_undamaged_testset_resized = np.array([resize(img, (128, 128, 3), mode='reflect', anti_aliasing=True) for img in X_test_undamaged_testset])\n",
    "X_test_damaged_testset_resized = np.array([resize(img, (128, 128, 3), mode='reflect', anti_aliasing=True) for img in X_test_damaged_testset])\n",
    "\n",
    "weights_directory = r\"D:\\SagharGhaffari\\ANN_Project\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the weights into the models with the full path\n",
    "generator.load_weights(os.path.join(weights_directory, \"generator_weights_epoch_8000.h5\"))\n",
    "discriminator.load_weights(os.path.join(weights_directory, \"discriminator_weights_epoch_8000.h5\"))\n",
    "repair_generator.load_weights(os.path.join(weights_directory, \"repair_generator_weights_epoch_8000.h5\"))\n",
    "\n",
    "# Sample noise and generate images using the generator\n",
    "num_samples = 50  # Adjust as needed\n",
    "noise = np.random.normal(0, 1, (num_samples, 100))\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "# Evaluate the generated images using the discriminator\n",
    "discriminator_loss = discriminator.evaluate(generated_images, np.zeros((num_samples, 1)))\n",
    "print(f\"Discriminator Loss on Generated Images: {discriminator_loss}\")\n",
    "\n",
    "\n",
    "# Test the repair generator on your test set\n",
    "test_loss = repair_generator.evaluate([X_test_undamaged_testset_resized, X_test_damaged_testset_resized], X_test_undamaged_testset_resized)\n",
    "print(f\"Repair Generator Test Loss: {test_loss}\")\n",
    "\n",
    "# Visualize and save the generated images\n",
    "save_generated_images(8000, repair_generator, output_path, X_test_undamaged_testset, X_test_damaged_testset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
